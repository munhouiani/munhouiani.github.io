<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"blog.munhou.com","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.27.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":true,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="What is Out-of-Distribution (OOD) Detection and Why is it Important?Most machine learning models are trained based on the closed-world assumption, meaning that the test data is assumed to have the sam">
<meta property="og:type" content="article">
<meta property="og:title" content="Detecting Out-of-Distribution Samples with kNN">
<meta property="og:url" content="https://blog.munhou.com/2022/12/01/Detecting%20Out-of-Distribution%20Samples%20with%20Knn/index.html">
<meta property="og:site_name" content="Mun Hou&#39;s Blog">
<meta property="og:description" content="What is Out-of-Distribution (OOD) Detection and Why is it Important?Most machine learning models are trained based on the closed-world assumption, meaning that the test data is assumed to have the sam">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://blog.munhou.com/images/ood-knn/2022-12-01T170823.png">
<meta property="og:image" content="https://blog.munhou.com/images/ood-knn/2022-12-01T173157.png">
<meta property="og:image" content="https://blog.munhou.com/images/ood-knn/2022-12-03T153545.png">
<meta property="article:published_time" content="2022-12-01T16:17:48.000Z">
<meta property="article:modified_time" content="2026-01-14T23:03:39.756Z">
<meta property="article:author" content="Mun Hou">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="PyTorch">
<meta property="article:tag" content="Machine Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog.munhou.com/images/ood-knn/2022-12-01T170823.png">


<link rel="canonical" href="https://blog.munhou.com/2022/12/01/Detecting%20Out-of-Distribution%20Samples%20with%20Knn/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://blog.munhou.com/2022/12/01/Detecting%20Out-of-Distribution%20Samples%20with%20Knn/","path":"2022/12/01/Detecting Out-of-Distribution Samples with Knn/","title":"Detecting Out-of-Distribution Samples with kNN"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Detecting Out-of-Distribution Samples with kNN | Mun Hou's Blog</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-345528590"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"G-345528590","only_pageview":false,"measure_protocol_api_secret":null}</script>
  <script src="/js/third-party/analytics/google-analytics.js" defer></script>








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script><script src="/js/bookmark.js" defer></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Mun Hou's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#What-is-Out-of-Distribution-OOD-Detection-and-Why-is-it-Important"><span class="nav-number">1.</span> <span class="nav-text">What is Out-of-Distribution (OOD) Detection and Why is it Important?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#How-is-OOD-Detection-Methods-Evaluted"><span class="nav-number">2.</span> <span class="nav-text">How is OOD Detection Methods Evaluted?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OOD-Detection-Methods"><span class="nav-number">3.</span> <span class="nav-text">OOD Detection Methods</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Using-kNN-as-an-OOD-Detector"><span class="nav-number">4.</span> <span class="nav-text">Using kNN as an OOD Detector</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Out-of-Distribution-Detection-for-Single-Feature"><span class="nav-number">4.1.</span> <span class="nav-text">Out-of-Distribution Detection for Single Feature</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Core-Idea-Embedding"><span class="nav-number">4.2.</span> <span class="nav-text">Core Idea: Embedding</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Train-Resnet18-on-CIFAR-10"><span class="nav-number">4.3.</span> <span class="nav-text">Train Resnet18 on CIFAR-10</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Extraction"><span class="nav-number">4.4.</span> <span class="nav-text">Feature Extraction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Find-k-Nearest-Neighbors-with-FAISS"><span class="nav-number">4.5.</span> <span class="nav-text">Find $k$-Nearest Neighbors with FAISS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Evaluate-on-OOD-Data"><span class="nav-number">4.6.</span> <span class="nav-text">Evaluate on OOD Data</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References"><span class="nav-number">5.</span> <span class="nav-text">References</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Mun Hou</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">17</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/munhouiani" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;munhouiani" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:munhou2022+blog@gmail.com" title="E-Mail → mailto:munhou2022+blog@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blog.munhou.com/2022/12/01/Detecting%20Out-of-Distribution%20Samples%20with%20Knn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Mun Hou">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mun Hou's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Detecting Out-of-Distribution Samples with kNN | Mun Hou's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Detecting Out-of-Distribution Samples with kNN
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-12-02 00:17:48" itemprop="dateCreated datePublished" datetime="2022-12-02T00:17:48+08:00">2022-12-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2026-01-15 07:03:39" itemprop="dateModified" datetime="2026-01-15T07:03:39+08:00">2026-01-15</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2022/12/01/Detecting%20Out-of-Distribution%20Samples%20with%20Knn/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2022/12/01/Detecting Out-of-Distribution Samples with Knn/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="What-is-Out-of-Distribution-OOD-Detection-and-Why-is-it-Important"><a href="#What-is-Out-of-Distribution-OOD-Detection-and-Why-is-it-Important" class="headerlink" title="What is Out-of-Distribution (OOD) Detection and Why is it Important?"></a>What is Out-of-Distribution (OOD) Detection and Why is it Important?</h2><p>Most machine learning models are trained based on the closed-world assumption, meaning that the test data is assumed to have the same distribution as the training data. When we train a model, we usually form our training and testing data by randomly splitting the data we have into two sets, in which both datasets have the same label distribution. However, in the real-world scenario, this assumption doesn’t necessarily hold. For example, a model trained to classify cats and dogs may receive an image of a dolphin. Even worse, it might highly confident classify such inputs into in-distribution classes. </p>
<img src="/images/ood-knn/2022-12-01T170823.png" alt="OOD Example" style="zoom:40%;" /> 

<p>Detecting if the received model inputs have the same distribution as the training data is called out-of-distribution detection. </p>
<span id="more"></span>

<p>OOD detection plays a crucial part in modern-day machine learning services. For example, we can use the OOD detector as part of the machine learning operations to detect unknown inputs. When an unknown is seen, the machine learning service can safely reject the input instead of returning an answer from the model.</p>
<img src="/images/ood-knn/2022-12-01T173157.png" alt="OOD Detector as a prefilter" style="zoom:35%;" /> 

<p>We can also use the result from an OOD detector as a filter for the data labeling task. For example, a machine learning service might receive a lot of inputs every day, and it is not feasible to let human labelers review all data. We can prioritize the process with an OOD detector by reviewing those out-of-distribution samples.</p>
<h2 id="How-is-OOD-Detection-Methods-Evaluted"><a href="#How-is-OOD-Detection-Methods-Evaluted" class="headerlink" title="How is OOD Detection Methods Evaluted?"></a>How is OOD Detection Methods Evaluted?</h2><p>OOD detection can be seen as a binary classification problem. We often start by training a model with a dataset known as the in-distribution dataset, i.e., CIFAR-10. To evaluate an OOD detector, we will prepare another dataset not in the same domain as the training data, i.e., SHVN, known as the out-of-distribution dataset. We then combine these two datasets to check if the OOD detection knows which is from the in-distribution dataset and vice versa. We usually use label 1 (positive) for in-distribution and 0 (negative) for the out-distribution. Aside from the standard evaluation metrics, we also calculate the FP rate of the OOD detector when its TP rate is at 95%, denoted as FPR@TPR95.</p>
<h2 id="OOD-Detection-Methods"><a href="#OOD-Detection-Methods" class="headerlink" title="OOD Detection Methods"></a>OOD Detection Methods</h2><p>From <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2110.11334">a comprehensive study by J. Yang et al.</a>, OOD detections methods can be categorized into:</p>
<ol>
<li>Classification methods</li>
<li>Density-based methods</li>
<li>Distance-based methods</li>
<li>Reconstruction-based methods</li>
</ol>
<h2 id="Using-kNN-as-an-OOD-Detector"><a href="#Using-kNN-as-an-OOD-Detector" class="headerlink" title="Using kNN as an OOD Detector"></a>Using kNN as an OOD Detector</h2><p>The following sections are notes and implementation of a paper by Y. Sun et al.: <em>Out-of-distribution detection with deep nearest neighbors</em>.</p>
<h3 id="Out-of-Distribution-Detection-for-Single-Feature"><a href="#Out-of-Distribution-Detection-for-Single-Feature" class="headerlink" title="Out-of-Distribution Detection for Single Feature"></a>Out-of-Distribution Detection for Single Feature</h3><p>Before we dive into the kNN method, let’s see how out-of-distribution detection works on a single feature. For example, let’s say we have a feature $p$ that is normally distributed with a mean of $0$ and standard deviation of $1$, and $q$ is also drawn i.i.d. from the same distribution.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> wasserstein_distance</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># p and q from the same distribution, both has 1000 samples</span></span><br><span class="line">p = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, size=<span class="number">1000</span>)</span><br><span class="line">q = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, size=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># check the wasserstein_distance: 0.04247616759945748</span></span><br><span class="line">wasserstein_distance(p, q)</span><br><span class="line"></span><br><span class="line"><span class="comment"># q is drawn from the different distribution</span></span><br><span class="line">q = np.random.normal(<span class="number">3</span>, <span class="number">5</span>, size=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># larger wasserstein_distance: 4.170158238494999</span></span><br><span class="line">wasserstein_distance(p, q)</span><br></pre></td></tr></table></figure>

<p>We can use statistical distance measures, such as Wasserstein distance, to check if $p$ and $q$ have the same distribution. If they have the same distribution, the Wasserstein distance will be small. Otherwise, the resulting Wasserstein distance is large.</p>
<p>Traditional statistical distance measures are no longer applied to deep learning models because the inputs are very high-dimensional. Take a $32 \times 32$ color image as an example, its dimension is $32 \times 32 \times 3 &#x3D; 3072$. Therefore, calculating statistical distance measures for all features is not feasible.</p>
<h3 id="Core-Idea-Embedding"><a href="#Core-Idea-Embedding" class="headerlink" title="Core Idea: Embedding"></a>Core Idea: Embedding</h3><p>Regarding deep learning models with high dimensional features, current OOD methods focus on the embedding space of a <strong>well-trained</strong> model. Distance-based methods assume that in the embedding space, OOD samples are relatively far away from in-distribution data. Density-based methods believe that in-distribution data follow certain probability distributions. Hence data falls into low-density regions are OOD. </p>
<img src="/images/ood-knn/2022-12-03T153545.png" alt="Embedding space" style="zoom:35%;" /> 

<p>However, these assumptions may not hold. Instead of imposing strong assumptions on the underlying embedding space, Y. Sun et al. use kNN, which is distributional assumption-free. Their algorithm is simple. First, they will gather distances of $k$-nearest neighbor of all in-distribution samples, then use those distances to determine a threshold. Any test data with a kNN distance larger than the threshold are flagged as OOD.</p>
<h3 id="Train-Resnet18-on-CIFAR-10"><a href="#Train-Resnet18-on-CIFAR-10" class="headerlink" title="Train Resnet18 on CIFAR-10"></a>Train Resnet18 on CIFAR-10</h3><p>We first train a ResNet18 model with CIFAR-10 data to demonstrate their approaches. This training code is slightly modified from the <a target="_blank" rel="noopener" href="https://pytorch-lightning.readthedocs.io/en/stable/notebooks/lightning_examples/cifar10-baseline.html">official Pytorch Lightning tutorial</a>. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LitResnet</span>(<span class="title class_ inherited__">LightningModule</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, lr=<span class="number">0.05</span>, num_classes=<span class="number">10</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.save_hyperparameters()</span><br><span class="line">        <span class="variable language_">self</span>.model = create_model()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = <span class="variable language_">self</span>.model(x)</span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(out, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">features</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.model.conv1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.model.bn1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.model.relu(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.model.maxpool(x)</span><br><span class="line"></span><br><span class="line">        x = <span class="variable language_">self</span>.model.layer1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.model.layer2(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.model.layer3(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.model.layer4(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">training_step</span>(<span class="params">self, batch, batch_idx</span>):</span><br><span class="line">        x, y = batch</span><br><span class="line">        logits = <span class="variable language_">self</span>(x)</span><br><span class="line">        loss = F.nll_loss(logits, y)</span><br><span class="line">        <span class="variable language_">self</span>.log(<span class="string">&quot;train_loss&quot;</span>, loss)</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">self, batch, stage=<span class="literal">None</span></span>):</span><br><span class="line">        x, y = batch</span><br><span class="line">        logits = <span class="variable language_">self</span>(x)</span><br><span class="line">        loss = F.nll_loss(logits, y)</span><br><span class="line">        preds = torch.argmax(logits, dim=<span class="number">1</span>)</span><br><span class="line">        acc = accuracy(preds, y, task=<span class="string">&quot;multiclass&quot;</span>, num_classes=num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> stage:</span><br><span class="line">            <span class="variable language_">self</span>.log(<span class="string">f&quot;<span class="subst">&#123;stage&#125;</span>_loss&quot;</span>, loss, prog_bar=<span class="literal">True</span>)</span><br><span class="line">            <span class="variable language_">self</span>.log(<span class="string">f&quot;<span class="subst">&#123;stage&#125;</span>_acc&quot;</span>, acc, prog_bar=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">validation_step</span>(<span class="params">self, batch, batch_idx</span>):</span><br><span class="line">        <span class="variable language_">self</span>.evaluate(batch, <span class="string">&quot;val&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_step</span>(<span class="params">self, batch, batch_idx</span>):</span><br><span class="line">        <span class="variable language_">self</span>.evaluate(batch, <span class="string">&quot;test&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">configure_optimizers</span>(<span class="params">self</span>):</span><br><span class="line">        optimizer = torch.optim.SGD(</span><br><span class="line">            <span class="variable language_">self</span>.parameters(),</span><br><span class="line">            lr=<span class="variable language_">self</span>.hparams.lr,</span><br><span class="line">            momentum=<span class="number">0.9</span>,</span><br><span class="line">            weight_decay=<span class="number">5e-4</span>,</span><br><span class="line">        )</span><br><span class="line">        scheduler_dict = &#123;</span><br><span class="line">            <span class="string">&quot;scheduler&quot;</span>: OneCycleLR(</span><br><span class="line">                optimizer,</span><br><span class="line">                <span class="number">0.1</span>,</span><br><span class="line">                epochs=<span class="variable language_">self</span>.trainer.max_epochs,</span><br><span class="line">                total_steps=<span class="variable language_">self</span>.trainer.estimated_stepping_batches,</span><br><span class="line">            ),</span><br><span class="line">            <span class="string">&quot;interval&quot;</span>: <span class="string">&quot;step&quot;</span>,</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;optimizer&quot;</span>: optimizer, <span class="string">&quot;lr_scheduler&quot;</span>: scheduler_dict&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">model = LitResnet(lr=<span class="number">0.05</span>, num_classes=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    max_epochs=<span class="number">30</span>,</span><br><span class="line">    accelerator=<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">    devices=<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">    logger=CSVLogger(save_dir=<span class="string">&quot;logs/&quot;</span>),</span><br><span class="line">    callbacks=[</span><br><span class="line">        LearningRateMonitor(logging_interval=<span class="string">&quot;step&quot;</span>),</span><br><span class="line">        TQDMProgressBar(refresh_rate=<span class="number">10</span>),</span><br><span class="line">    ],</span><br><span class="line">    deterministic=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer.fit(model, train_loader, val_loader)</span><br><span class="line">trainer.test(model, dataloaders=val_loader)</span><br></pre></td></tr></table></figure>

<p>This model achieves an accuracy of 94%.</p>
<h3 id="Feature-Extraction"><a href="#Feature-Extraction" class="headerlink" title="Feature Extraction"></a>Feature Extraction</h3><p>We use the output of the last hidden layer (one layer before the output layer) as the features. Then, we normalize the features with the method described in the paper $\mathbf{z} &#x3D; \phi(\mathbf{x}) &#x2F; || \phi(\mathbf{x}) ||_{2}$.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">extract_features</span>(<span class="params">model, dataloader</span>):</span><br><span class="line">    features = []</span><br><span class="line">    <span class="keyword">for</span> data, label <span class="keyword">in</span> dataloader:</span><br><span class="line">        <span class="comment"># get the last hidden layer&#x27;s output from model, size: (batch_size, 512, 4, 4)</span></span><br><span class="line">        x = model.features(data)</span><br><span class="line">        <span class="comment"># avg pool, size: (batch_size, 512, 1, 1)</span></span><br><span class="line">        x = F.adaptive_avg_pool2d(x, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># squeeze, size: (batch_size, 512)</span></span><br><span class="line">        x = x.squeeze()</span><br><span class="line">        <span class="comment"># detach</span></span><br><span class="line">        x = x.data.cpu().numpy()</span><br><span class="line"></span><br><span class="line">        features.append(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># merge as a large numpy array</span></span><br><span class="line">    features = np.vstack(features)</span><br><span class="line">    <span class="comment"># ensure data type</span></span><br><span class="line">    features = features.astype(np.float32)</span><br><span class="line">    <span class="comment"># normalization</span></span><br><span class="line">    features = features / (</span><br><span class="line">        np.linalg.norm(features, <span class="built_in">ord</span>=<span class="number">2</span>, axis=-<span class="number">1</span>, keepdims=<span class="literal">True</span>) + <span class="number">1e-10</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> features</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_features = extract_features(model, train_loader)</span><br><span class="line">test_features = extract_features(model, val_loader)</span><br><span class="line">ood_features = extract_features(model, ood_loader)</span><br></pre></td></tr></table></figure>

<h3 id="Find-k-Nearest-Neighbors-with-FAISS"><a href="#Find-k-Nearest-Neighbors-with-FAISS" class="headerlink" title="Find $k$-Nearest Neighbors with FAISS"></a>Find $k$-Nearest Neighbors with FAISS</h3><p>We now need to find the distances of kNN and determine the threshold. First, we build an index using FAISS with the training features. Then we gather distances of $k$-th neighbors to the testing features. Here we set $k$ to 50. After that, we determine the threshold with 95% of TRP.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># build index with training features</span></span><br><span class="line">index = faiss.IndexFlatL2(train_features.shape[<span class="number">1</span>])</span><br><span class="line">index.add(train_features)</span><br><span class="line"></span><br><span class="line"><span class="comment"># find k-th neighbours and distances</span></span><br><span class="line">k = <span class="number">50</span></span><br><span class="line">in_l2_distances, in_k_closest_points = index.search(test_features, k)</span><br><span class="line"></span><br><span class="line"><span class="comment"># in_l2_distances is sorted increasingly</span></span><br><span class="line">in_scores = in_l2_distances[:, -<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># determine threshold with TPR = 0.95</span></span><br><span class="line">in_scores.sort()</span><br><span class="line">threshold = in_scores[<span class="built_in">round</span>(<span class="number">0.95</span> * <span class="built_in">len</span>(in_scores))]</span><br></pre></td></tr></table></figure>

<h3 id="Evaluate-on-OOD-Data"><a href="#Evaluate-on-OOD-Data" class="headerlink" title="Evaluate on OOD Data"></a>Evaluate on OOD Data</h3><p>We follow the same steps as above for the OOD data. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># same as in-distribution data</span></span><br><span class="line">k = <span class="number">50</span></span><br><span class="line">out_l2_distances, out_k_closest_points = index.search(ood_features, k)</span><br><span class="line"></span><br><span class="line"><span class="comment"># out_l2_distances is sorted increasingly</span></span><br><span class="line">out_scores = out_l2_distances[:, -<span class="number">1</span>]</span><br></pre></td></tr></table></figure>

<p>After getting the distances of $k$-th nearest neighbors of the OOD data, we can easily find the result by checking if the distance is greater than the threshold.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">tp = <span class="number">0</span></span><br><span class="line">tn = <span class="number">0</span></span><br><span class="line">fp = <span class="number">0</span></span><br><span class="line">fn = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> point <span class="keyword">in</span> in_scores:</span><br><span class="line">    <span class="keyword">if</span> point &lt;= threshold:</span><br><span class="line">        tp += <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        fn += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> point <span class="keyword">in</span> out_scores:</span><br><span class="line">    <span class="keyword">if</span> point &lt;= threshold:</span><br><span class="line">        fp += <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        tn += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">tp_rate = tp / (tp + fn)</span><br><span class="line">tn_rate = tn / (tn + fp)</span><br><span class="line">fp_rate = fp / (fp + tn)</span><br><span class="line">fn_rate = fn / (fn + tp)</span><br><span class="line"></span><br><span class="line">result = &#123;</span><br><span class="line">    <span class="string">&quot;tp&quot;</span>: tp,</span><br><span class="line">    <span class="string">&quot;tn&quot;</span>: tn,</span><br><span class="line">    <span class="string">&quot;fp&quot;</span>: fp,</span><br><span class="line">    <span class="string">&quot;fn&quot;</span>: fn,</span><br><span class="line">    <span class="string">&quot;tpr&quot;</span>: tp_rate,</span><br><span class="line">    <span class="string">&quot;fpr&quot;</span>: fp_rate,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>The final result has an FPR@TPR95 of 37.45%, higher than the paper’s result of 24.53%. Developing an OOD detector depends on the quality of the model. The paper mentioned that we could improve the result by using contrastive learning. Contrastive learning helps bring data with the same label closer and push data with different labels further, which aligns with the usage of kNN.</p>
<p>Checkout the full notebook here: <a target="_blank" rel="noopener" href="https://github.com/munhouiani/ood-knn">https://github.com/munhouiani/ood-knn</a></p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol>
<li>J. Yang, K. Zhou, Y. Li, and Z. Liu, “Generalized out-of-distribution detection: A survey”, <em>CoRR</em>, vol. abs&#x2F;2110.11334, 2021, [Online]. Available: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2110.11334">https://arxiv.org/abs/2110.11334</a></li>
<li>J. Ren and B. Lakshminarayanan, “Improving Out-of-Distribution Detection in Machine Learning Models”, <em>Google Research Blog</em>, Dec. 17, 2019. <a target="_blank" rel="noopener" href="https://ai.googleblog.com/2019/12/improving-out-of-distribution-detection.html">https://ai.googleblog.com/2019/12/improving-out-of-distribution-detection.html</a> (accessed Dec. 02, 2022).</li>
<li>Y. Sun, Y. Ming, X. Zhu, and Y. Li, “Out-of-distribution detection with deep nearest neighbors”, 2022.</li>
<li>PL team, “PyTorch Lightning CIFAR10 ~94% Baseline Tutorial”, <em>Pytorch Lightning</em>, Apr. 28, 2022. <a target="_blank" rel="noopener" href="https://pytorch-lightning.readthedocs.io/en/stable/notebooks/lightning_examples/cifar10-baseline.html">https://pytorch-lightning.readthedocs.io/en/stable/notebooks/lightning_examples/cifar10-baseline.html</a> (accessed Dec. 02, 2022).</li>
<li>P. Mardziel, “Drift Metrics: How to Select the Right Metric to Analyze Drift”, <em>Toward Data Science</em>, Dec. 06, 2021. <a target="_blank" rel="noopener" href="https://towardsdatascience.com/drift-metrics-how-to-select-the-right-metric-to-analyze-drift-24da63e497e">https://towardsdatascience.com/drift-metrics-how-to-select-the-right-metric-to-analyze-drift-24da63e497e</a> (accessed Dec. 03, 2022).</li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
              <a href="/tags/PyTorch/" rel="tag"># PyTorch</a>
              <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/02/09/Simple-Implementation-of-Rendevzous-Architecture-for-Machine-Learning-Services/" rel="prev" title="Simple Implementation of Rendezvous Architecture for Machine Learning Services">
                  <i class="fa fa-angle-left"></i> Simple Implementation of Rendezvous Architecture for Machine Learning Services
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/03/01/Importance-Sampling/" rel="next" title="Importance Sampling">
                  Importance Sampling <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2026</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Mun Hou</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/munhouiani" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>
<script class="next-config" data-name="disqus" type="application/json">{"enable":true,"shortname":"munhousblog","count":true,"i18n":{"disqus":"disqus"}}</script>
<script src="/js/third-party/comments/disqus.js" defer></script>

</body>
</html>
